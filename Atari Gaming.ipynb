{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we attempt to develop Deep Q-Networks for agents to learn Atari games, including the famous Breakout. OpenAI Gym's environment rendering provides individual frames which are preprocessed and fed to a state-action network to learn optimal behaviour. Epsilon-Greedy exploration is used where epsilon is gradually adjusted over time. We attempt to reproduce DeepMind's 2013 paper in terms of neural network architecture to teach the agent. In accordance with the paper, we repeat each chosen action for k frames (k=4), and hence each action decision involves accessing four consecutive frames in a convolutional net. Grayscaling and downsampling preprocessing is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import collections\n",
    "import itertools\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Lambda, Flatten, Input, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> SECTION 1: Preprocessing and Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocessing(framelist):\n",
    "    frames = np.zeros((np.int(framelist[0].shape[0]/2), np.int(framelist[0].shape[1]/2), 4), dtype=np.float64)\n",
    "    for i in range(4):\n",
    "        frames[:,:,i] = np.mean(framelist[i], axis=2)[::2,::2]\n",
    "    return frames\n",
    "#Example State Fed to Network\n",
    "env = gym.make(\"BreakoutDeterministic-v4\")\n",
    "frame = env.reset()\n",
    "framelist = collections.deque()\n",
    "actions = [1,2,3,2]\n",
    "for i in range(4):\n",
    "    frame, reward, is_done, _ = env.step(actions[i])\n",
    "    framelist.append(frame)\n",
    "frames = preprocessing(framelist)\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.suptitle(\"4-Frame Pixel State for Atari\")\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(frames[:,:,i], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 105, 80, 4)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 25, 19, 16)   4112        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 25, 19, 16)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 11, 8, 32)    8224        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2816)         0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          721152      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            1028        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 4)            0           dense_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 734,516\n",
      "Trainable params: 734,516\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(env, imgheight, imgwidth):\n",
    "    tf.keras.backend.clear_session()\n",
    "    mask = Input((len(env.unwrapped.get_action_meanings()),))\n",
    "    frameinp = Input((imgheight, imgwidth, 4))\n",
    "    conv1 = Conv2D(filters=16, kernel_size=(8,8), strides=4, padding=\"valid\")(frameinp)\n",
    "    activ1 = tf.keras.layers.LeakyReLU(alpha=0.2)(conv1)\n",
    "    conv2 = Conv2D(filters=32, kernel_size=(4,4), strides=2, padding=\"valid\", activation=\"relu\")(activ1)\n",
    "    dense = Dense(units=256, activation=\"relu\")(Flatten()(conv2))\n",
    "    rawoutput = Dense(units=len(env.unwrapped.get_action_meanings()), activation=None)(dense)\n",
    "    finaloutput = Lambda(lambda tensors: tf.math.multiply(tensors[0], tensors[1]))([rawoutput, mask])\n",
    "    mdl = Model(inputs=[mask, frameinp], outputs=finaloutput)\n",
    "    mdl.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4))\n",
    "    return mdl\n",
    "build_model(env, 105, 80).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SECTION 2: Experience Replay</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay():\n",
    "    def __init__(self, buffersize, batchsize):\n",
    "        self.buffersize, self.batchsize = buffersize, batchsize\n",
    "        self.sars = collections.deque()\n",
    "        self.cursize = 0\n",
    "    def add(self, state1, action, reward, state2):\n",
    "        while self.cursize>=self.buffersize:\n",
    "            self.sars.popleft()\n",
    "            self.cursize-=1\n",
    "        self.sars.append((state1, action, reward, state2))\n",
    "        self.cursize+=1\n",
    "    def sample(self, env):\n",
    "        if self.cursize==0: return\n",
    "        replacer = True if self.cursize<self.batchsize else False\n",
    "        indices = np.random.choice(self.cursize, self.batchsize, replace=replacer)\n",
    "        state1 = np.zeros((self.batchsize, self.sars[0][0].shape[0], \n",
    "                           self.sars[0][0].shape[1], self.sars[0][0].shape[2]))\n",
    "        reward = np.zeros(self.batchsize)\n",
    "        action = np.zeros((self.batchsize, len(env.unwrapped.get_action_meanings())))\n",
    "        state2 = np.zeros((self.batchsize, self.sars[0][0].shape[0], \n",
    "                           self.sars[0][0].shape[1], self.sars[0][0].shape[2]))\n",
    "        for i in range(len(indices)):\n",
    "            data = self.sars[indices[i]]\n",
    "            state1[i], reward[i], state2[i] = data[0], data[2], data[3]\n",
    "            action[i,data[1]] = 1\n",
    "        return state1, action, reward, state2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SECTION 3: Episodic Training </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action(model, state, env, epsilon):\n",
    "    prob, action = np.random.uniform(), None\n",
    "    if prob<(1-epsilon):\n",
    "        actionvalues = model.predict([np.ones((1,len(env.unwrapped.get_action_meanings()))), np.array([state])])[0]\n",
    "        maxval = np.max(actionvalues)\n",
    "        bestactions = np.where(actionvalues==np.max(actionvalues))[0]\n",
    "        return np.random.choice(bestactions)\n",
    "    else:\n",
    "        return np.random.choice(len(env.unwrapped.get_action_meanings()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dq_model_trainer(exprep, model, env):\n",
    "    state1, action, reward, state2 = exprep.sample(env)\n",
    "    futactions = model.predict([np.ones((state2.shape[0], len(env.unwrapped.get_action_meanings()))), state2])\n",
    "    futactions = np.max(futactions, axis=1)\n",
    "    target = (0.99*futactions+reward).reshape(-1,1)*action\n",
    "    model.fit([action, state1], target, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_episode(model, env, epsilon, exprep):\n",
    "    frame = env.reset()\n",
    "    framelist = collections.deque([deepcopy(frame) for _ in range(4)])\n",
    "    rewardlist = collections.deque([0,0,0,0])\n",
    "    state1 = preprocessing(framelist)\n",
    "    while True:\n",
    "        action1 = epsilon_greedy_action(model, state1, env, epsilon)\n",
    "        frame, reward, is_done, ot = env.step(action1)\n",
    "        framelist.popleft()\n",
    "        framelist.append(frame)\n",
    "        rewardlist.popleft()\n",
    "        rewardlist.append(reward)\n",
    "        if is_done:\n",
    "            dq_model_trainer(exprep, model, env)\n",
    "            return\n",
    "        state2 = preprocessing(framelist)\n",
    "        exprep.add(state1, action1, sum(rewardlist), state2)\n",
    "        state1 = deepcopy(state2)\n",
    "        if exprep.cursize>(2*exprep.batchsize):\n",
    "            dq_model_trainer(exprep, model, env)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_scheduler(numepisodes, curep):\n",
    "    #According to DeepMind's 2013 paper, we reduce epsilon from 1.0 to 0.1 over time, and then constant\n",
    "    #Let us decay linearly to 0.1 within a third of numepisodes\n",
    "    if numepisodes<=3:\n",
    "        return 1.0 if curep==1 else 0.1\n",
    "    slope = -0.9/(numepisodes/3-1)\n",
    "    intercept = 1-slope\n",
    "    return slope*curep+intercept if curep<=np.int(numepisodes/3) else 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atari_trainer(gamename, numepisodes):\n",
    "    env = gym.make(gamename+\"Deterministic-v4\") \n",
    "    model = build_model(env, 105, 80)\n",
    "    start = time.time()\n",
    "    exprep = ExperienceReplay(2000, 32)\n",
    "    for i in range(1,numepisodes+1):\n",
    "        one_episode(model, env, epsilon_scheduler(numepisodes,i), exprep)\n",
    "        print(time.time()-start)\n",
    "        if (i%np.int(numepisodes/10))==0:\n",
    "            print(\"Iteration Update at Episode No. \"+str(i)+\"(Time=\"+str(time.time()-start)+\")\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> SECTION 4: Learning Visualization </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_visual(model, env, epsilon, filename):\n",
    "    frame = env.reset()\n",
    "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    video = cv2.VideoWriter()\n",
    "    success = video.open(filename+\".mov\", fourcc, 30, (160,210), True)\n",
    "    video.write(frame.astype(\"uint8\"))\n",
    "    framelist = collections.deque([deepcopy(frame) for _ in range(4)])\n",
    "    is_done = False\n",
    "    while not is_done:\n",
    "        state1 = preprocessing(framelist)\n",
    "        action1 = epsilon_greedy_action(model, state1, env, epsilon)\n",
    "        frame, reward, is_done, ot = env.step(action1)\n",
    "        framelist.popleft()\n",
    "        framelist.append(frame)\n",
    "        video.write(frame.astype(\"uint8\"))\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
