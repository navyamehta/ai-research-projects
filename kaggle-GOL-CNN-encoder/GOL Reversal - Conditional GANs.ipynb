{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out Kaggle at https://www.kaggle.com/c/conways-reverse-game-of-life-2020. The objective is to reverse Conway's Game of Life Board (25x25 cells) to learn its position $\\delta$ steps ago ($1<=\\delta<=5$). In this notebook, we adapt \"Image-to-Image Translation with Conditional Adverserial Networks\" (Isola et al., 2017) by training a discriminator and generator conditioned on input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import collections\n",
    "import gc\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Lambda, Flatten, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dropout, GaussianNoise, Input, UpSampling2D, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "import sklearn.model_selection\n",
    "from copy import deepcopy\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Exited in 5.894061088562012 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50000, 1252), (50000, 25, 25, 1), (50000, 5), (50000, 25, 25, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "data = pd.read_csv(\"./train.csv\")\n",
    "X1 = data[data.columns[np.vectorize(lambda s: \"stop\" in s)(data.columns.values)]]\n",
    "X1 = X1.values.reshape(data.shape[0],25,25,1)\n",
    "delta = data[\"delta\"].values\n",
    "X2 = np.zeros((data.shape[0],5))\n",
    "for i in range(data.shape[0]):\n",
    "    X2[i,delta[i]-1] = 1\n",
    "Y = data[data.columns[np.vectorize(lambda s: \"start\" in s)(data.columns.values)]]\n",
    "Y = Y.values.reshape(data.shape[0],25,25,1)\n",
    "print(\"Preprocessing Exited in \"+str(time.time()-start)+\" seconds\")\n",
    "data.shape, X1.shape, X2.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> SECTION 1: Building the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(inp, out, mask, size):\n",
    "    indices = np.random.choice(inp.shape[0], size=size, replace=False)\n",
    "    return inp[indices], out[indices], mask[indices], mask[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(lr=2e-3):\n",
    "    tf.keras.backend.clear_session()\n",
    "    curimg, befimg = Input((25,25,1)), Input((25,25,1))\n",
    "    imginp = Concatenate()([curimg, befimg])\n",
    "    mask = Input((5,))\n",
    "    #Increasing Filters to Capture Relationship\n",
    "    conv1 = Conv2D(filters=32, kernel_size=(7,7), strides=(1,1), padding=\"same\", activation=\"relu\")(imginp)\n",
    "    max1 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\")(conv1)\n",
    "    conv2 = Conv2D(filters=64, kernel_size=(7,7), strides=(1,1), padding=\"same\", activation=\"relu\")(max1)\n",
    "    max2 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\")(conv2)\n",
    "    #BatchNormalization for Train-Time Stability\n",
    "    max2 = BatchNormalization()(max2)\n",
    "    #Reducing Filters to 5-Channel Layer\n",
    "    conv3 = Conv2D(filters=32, kernel_size=(7,7), strides=(1,1), padding=\"same\", activation=\"relu\")(max2)\n",
    "    max3 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"valid\")(conv3)\n",
    "    fconv = Conv2D(filters=5, kernel_size=(7,7), strides=(1,1), padding=\"same\", activation=\"relu\")(max3)\n",
    "    #Discriminate on Relevant Delta\n",
    "    final = Dense(5, activation=\"sigmoid\")(Flatten()(fconv))\n",
    "    final = tf.math.multiply(final,mask)\n",
    "    model = Model(inputs=[curimg, befimg, mask], outputs=final)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=tf.keras.optimizers.Adam(lr=lr), loss_weights=[0.5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 25, 25, 1), (40000, 25, 25, 1), (40000, 5), (40000, 5))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "R1, R2, R3, R = generate_real_samples(X1[:40000],Y[:40000],X2[:40000], 20000)\n",
    "F1, F2, F3, F = generate_fake_samples(X1[:40000],Y[:40000],X2[:40000], 20000)\n",
    "indices=np.random.choice(40000,40000,replace=False)\n",
    "I1, I2 = np.concatenate([R1,F1])[indices], np.concatenate([R2,F2])[indices]\n",
    "I3, O = np.concatenate([R3,F3])[indices], np.concatenate([R,F])[indices]\n",
    "I1.shape, I2.shape, I3.shape, O.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 25, 25, 1), (10000, 25, 25, 1), (10000, 5), (10000, 5))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "VR1, VR2, VR3, VR = generate_real_samples(X1[40000:],Y[40000:],X2[40000:], 5000)\n",
    "VF1, VF2, VF3, VF = generate_fake_samples(X1[40000:],Y[40000:],X2[40000:], 5000)\n",
    "indices=np.random.choice(10000,10000,replace=False)\n",
    "VI1, VI2 = np.concatenate([VR1,VF1])[indices], np.concatenate([VR2,VF2])[indices]\n",
    "VI3, VO = np.concatenate([VR3,VF3])[indices], np.concatenate([VR,VF])[indices]\n",
    "VI1.shape, VI2.shape, VI3.shape, VO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
